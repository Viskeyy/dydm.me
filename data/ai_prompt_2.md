---
title: '两篇关于 prompt 的论文'
date: 2024-09-05
tags: ['prompt']
type: 'DefaultPost'
---

## 两篇关于大模型 (LLMs) prompt 的论文

### [A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications](https://arxiv.org/pdf/2402.07927)

> The following is generated by AI

这篇论文对大型语言模型（LLMs）中的提示工程技术进行了系统性的调查，并按照应用领域对这些技术进行了分类和概述。论文的主要观点可以总结为以下几点：

1. 提示工程技术的重要性：
    * 提示工程作为一种无需修改模型参数即可提升模型性能的技术，在扩展LLMs和视觉语言模型（VLMs）能力方面发挥着不可或缺的作用。
    * 通过精心设计的任务特定指令（提示），提示工程能够引导模型行为，使其在无需重新训练或进行大量微调的情况下，在各种任务和领域中表现出色。
    * 提示工程技术改变了传统的模型训练方式，推动了人工智能的发展，并开启了无限的可能性。

2. 提示工程技术的发展：
    * 论文详细介绍了从零样本提示、少样本提示到“思维链”提示等最新的提示工程技术，并对其应用领域、模型和数据进行了解析。
    * 论文分析了每种技术的优缺点，并探讨了其相对效能。
    * 论文还揭示了一个全面的分类图，展示了这些技术在LLM能力范围内的应用情况。

3. 提示工程技术的应用：
    * 无需大量训练的新任务： 零样本提示和少样本提示等技术在处理新任务时无需大量训练数据，具有很高的灵活性。
    * 推理和逻辑： “思维链”提示、自动思维链提示、自洽性、逻辑思维链提示等技术能够提升LLMs在复杂推理任务中的表现。
    * 减少幻觉： 检索增强生成（RAG）、ReAct提示、思维链验证提示等技术能够减少LLMs在生成文本时的幻觉和错误。
    * 用户界面： 主动提示技术能够提升LLMs在复杂问答任务中的表现。
    * 微调和优化： 自动提示工程师（APE）能够自动生成和选择最佳的提示，提升LLMs的性能。
    * 基于知识的推理和生成： 自动推理和工具使用（ART）技术能够使LLMs进行多步推理并整合外部工具的知识。
    * 提高一致性和连贯性： 对比思维链提示（CCoT）技术能够通过学习错误来提升LLMs的推理能力。
    * 管理情绪和语调： 情感提示技术能够增强LLMs对情绪线索的理解和处理能力。
    * 代码生成和执行： 程序思维提示（PoT）、结构化思维链提示（SCoT）、代码链提示（CoC）等技术能够提升LLMs在代码生成任务中的表现。
    * 优化和效率： 优化提示（OPRO）技术能够利用LLMs进行优化任务。
    * 理解用户意图： 重述和响应（RaR）提示技术能够提升LLMs对用户意图的理解。
    * 元认知和自我反思： 退一步提示技术能够提升LLMs在复杂推理任务中的表现。

4. 提示工程技术的未来：
    * 论文指出，尽管提示工程技术取得了显著的成功，但仍面临着一些挑战，例如偏见、事实不准确和可解释性不足等。
    * 论文认为，未来提示工程技术的方向包括元学习和混合提示架构等，这些技术有望进一步提升LLMs的能力。
    * 论文强调了在发展提示工程技术时需要考虑伦理问题，确保其以负责任的方式应用于我们的生活。

### [Large Language Models are Zero-Shot Reasoners](https://arxiv.org/pdf/2205.11916)

> The following is generated by AI

这篇论文的主要观点是，大型语言模型（LLMs）即使在没有微调或提供示例的情况下，也能在需要复杂推理的任务中表现出色。论文的核心发现是，通过添加一个简单的提示“让我们一步步思考”，LLMs 就能生成合理的推理路径并得出正确答案。

1. 论文证据和分析
    1. 链式思维提示（CoT）的局限性:
        * 论文指出，尽管 CoT 提示在需要多步推理的任务中取得了显著的性能提升，但它依赖于人工设计的示例，并且对每个任务需要进行特定的提示设计。这使得 CoT 提示的通用性和效率受限。
    2. 零样本链式思维（Zero-shot-CoT）的优势:
        * 论文提出了 Zero-shot-CoT，它通过添加“让我们一步步思考”提示来引导 LLM 进行推理。与 CoT 提示相比，Zero-shot-CoT 具有以下优势：
        * 通用性: Zero-shot-CoT 可以应用于各种推理任务，包括算术、符号推理、常识推理和其他逻辑推理任务，而无需为每个任务修改提示。
        * 效率: Zero-shot-CoT 无需人工设计示例，因此更高效且可扩展。
        * 鲁棒性: 论文通过实验表明，Zero-shot-CoT 对不同的提示模板和示例类型具有鲁棒性。
    3. 实验结果:
        * 论文在多个推理任务上评估了 Zero-shot-CoT，并与标准零样本提示、少样本提示和 CoT 提示进行了比较。主要发现如下：
            * Zero-shot-CoT 在算术推理任务（如 MultiArith 和 GSM8K）上取得了显著的性能提升，将准确率从 17.7% 提高到 78.7% 和 10.4% 提高到 40.7%。
            * Zero-shot-CoT 在符号推理任务和逻辑推理任务上也取得了显著的性能提升。
            * Zero-shot-CoT 在常识推理任务上的性能提升不如算术和逻辑推理任务，但生成的推理路径仍然具有逻辑性和合理性。
            * Zero-shot-CoT 的性能随着模型规模的增加而提高，这表明 LLM 的推理能力随着模型复杂度的增加而增强。
    4. 错误分析:
        * 论文对 Zero-shot-CoT 生成的推理路径进行了错误分析，发现其主要错误类型包括：
            * 不必要的推理步骤: 在得到正确预测后，Zero-shot-CoT 有时会继续进行不必要的推理步骤，导致最终预测错误。
            * 未开始推理: Zero-shot-CoT 有时只是重述输入问题，而没有进行推理。
            * 符号映射错误和计算错误: 这些错误通常是由于 LLM 的计算能力有限导致的。
    5. 提示选择的影响:
        * 论文研究了不同提示模板对 Zero-shot-CoT 性能的影响，发现鼓励推理的提示模板可以显著提高性能，而误导或不相关的提示模板则会导致性能下降。
    6. 与其他工作的比较:
        * 论文将 Zero-shot-CoT 与其他推理研究进行了比较，例如基于微调和少样本提示的研究。结果表明，Zero-shot-CoT 在不需要微调和人工设计示例的情况下，就能取得显著的推理性能提升。

2. 论文结论
    * 这篇论文表明，LLMs 具有强大的零样本推理能力，并且可以通过简单的提示来激发这种能力。
    * Zero-shot-CoT 是一种简单而有效的零样本提示方法，可以应用于各种推理任务，并显著提高 LLM 的推理性能。这项研究为进一步探索 LLM 的零样本能力提供了新的思路，并为开发更通用的语言模型奠定了基础。
